"""
Pydantic schemas for Debate System.

Week 5 Day 2: Multi-perspective analysis data structures.
"""

from enum import Enum
from dataclasses import dataclass
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field


class Perspective(str, Enum):
    """Debate perspective type."""
    BULL = 'bull'           # Optimistic view
    BEAR = 'bear'           # Pessimistic view
    NEUTRAL = 'neutral'     # Balanced analytical view


class ArgumentStrength(str, Enum):
    """Argument strength classification."""
    STRONG = 'strong'       # High confidence, backed by solid evidence
    MODERATE = 'moderate'   # Reasonable, some evidence
    WEAK = 'weak'           # Speculative, limited evidence


class Argument(BaseModel):
    """
    Single argument from a perspective.

    Example:
        Bull argument: "Strong revenue growth (+25% YoY) indicates healthy demand"
        Bear argument: "P/E ratio of 45 suggests overvaluation vs industry avg of 20"
    """
    perspective: Perspective = Field(..., description="Which perspective this argument supports")
    claim: str = Field(..., description="Main claim or assertion (1-2 sentences)")
    evidence: List[str] = Field(..., description="Supporting evidence from VerifiedFact")
    strength: ArgumentStrength = Field(..., description="How strong is this argument?")
    counterarguments: List[str] = Field(
        default_factory=list,
        description="Potential counterarguments (optional)"
    )
    confidence: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Confidence in this argument (0-1)"
    )


class DebateReport(BaseModel):
    """
    Complete debate report from one perspective.

    Contains all arguments generated by a single debater agent.
    """
    perspective: Perspective = Field(..., description="Which perspective this report represents")
    fact_id: str = Field(..., description="VerifiedFact being debated")

    arguments: List[Argument] = Field(..., description="All arguments from this perspective")

    # Summary
    key_points: List[str] = Field(
        ...,
        description="Top 3-5 key points (bullet format)"
    )
    overall_stance: str = Field(
        ...,
        description="Overall position in 2-3 sentences"
    )

    # Metadata
    num_strong_arguments: int = Field(
        default=0,
        description="Count of strong arguments"
    )
    average_confidence: float = Field(
        default=0.0,
        ge=0.0,
        le=1.0,
        description="Average confidence across all arguments"
    )


class Synthesis(BaseModel):
    """
    Final synthesis combining all perspectives.

    Produced by SynthesizerAgent after reviewing all debate reports.
    """
    fact_id: str = Field(..., description="VerifiedFact being analyzed")

    # Perspectives reviewed
    perspectives_reviewed: List[Perspective] = Field(
        ...,
        description="Which perspectives were included in synthesis"
    )

    # Synthesis content
    balanced_view: str = Field(
        ...,
        description="Balanced synthesis combining all perspectives (3-5 sentences)"
    )

    key_risks: List[str] = Field(
        ...,
        description="Top risks identified across perspectives"
    )
    key_opportunities: List[str] = Field(
        ...,
        description="Top opportunities identified across perspectives"
    )

    areas_of_agreement: List[str] = Field(
        default_factory=list,
        description="Points where all perspectives agree"
    )
    areas_of_disagreement: List[str] = Field(
        default_factory=list,
        description="Points of significant disagreement"
    )

    # Recommendation
    recommendation: str = Field(
        ...,
        description="Final recommendation or conclusion (2-3 sentences)"
    )

    # Confidence adjustment
    original_confidence: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Original VerifiedFact confidence"
    )
    adjusted_confidence: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Confidence after debate (may increase or decrease)"
    )
    confidence_rationale: str = Field(
        ...,
        description="Why confidence was adjusted"
    )

    # Quality metrics
    debate_quality_score: float = Field(
        default=0.0,
        ge=0.0,
        le=1.0,
        description="Quality of debate (diversity, depth, evidence)"
    )


@dataclass
class DebateContext:
    """
    Context for debate (input to debaters).

    Contains VerifiedFact + source code + query context.
    """
    fact_id: str
    extracted_values: Dict[str, Any]
    source_code: str
    query_text: str
    execution_metadata: Optional[Dict[str, Any]] = None
