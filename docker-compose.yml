# ============================================================================
# APE 2026 - Infrastructure Stack
# Week 7 Day 3 - Production Deployment Configuration
#
# Components:
# - API Service (FastAPI)
# - Neo4j (Episode Graph, Fact Lineage)
# - TimescaleDB (Time-Series OHLCV, Execution Logs)
# - Redis (Caching, Rate Limiting)
# - ChromaDB (Vector Store - embedded in API)
# - Prometheus + Grafana (Monitoring)
#
# Team: 1-2 developers
# Environment: Windows WSL2 / Linux / macOS
# ============================================================================

name: ape-2026

services:
  # ============================================================================
  # API Service (FastAPI)
  # ============================================================================
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: ape-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - ENV=production
      - LOG_LEVEL=info
      - CLAUDE_API_KEY=${CLAUDE_API_KEY}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - POSTGRES_HOST=timescaledb
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-ape_timeseries}
      - POSTGRES_USER=${POSTGRES_USER:-ape}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-ape_timescale_password}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-ape_neo4j_password}
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - vee_workspace:/app/vee/workspace
    depends_on:
      timescaledb:
        condition: service_healthy
      redis:
        condition: service_healthy
      neo4j:
        condition: service_healthy
    networks:
      - ape-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
  # ============================================================================
  # Neo4j - Episode Graph, Fact Lineage, ADR Tracking
  # ============================================================================
  neo4j:
    image: neo4j:5.14-community
    container_name: ape-neo4j
    restart: unless-stopped

    ports:
      - "7475:7474"  # HTTP (browser UI)
      - "7688:7687"  # Bolt protocol

    environment:
      # Authentication
      - NEO4J_AUTH=${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-ape_neo4j_password}

      # Memory settings (dev: 2GB heap, prod: 4GB)
      - NEO4J_server_memory_heap_initial__size=512m
      - NEO4J_server_memory_heap_max__size=2g
      - NEO4J_server_memory_pagecache_size=1g

      # Performance tuning
      - NEO4J_dbms_memory_transaction_total_max=512m
      - NEO4J_dbms_connector_bolt_thread__pool__max__size=400

      # Logging
      - NEO4J_dbms_logs_query_enabled=INFO
      - NEO4J_dbms_logs_query_threshold=1s

    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins

    healthcheck:
      test: ["CMD", "neo4j", "status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s

    networks:
      - ape-network

  # ============================================================================
  # TimescaleDB - Time-Series (OHLCV, Execution Logs)
  # ============================================================================
  timescaledb:
    image: timescale/timescaledb:latest-pg16
    container_name: ape-timescaledb
    restart: unless-stopped

    ports:
      - "5433:5432"

    environment:
      # Authentication
      - POSTGRES_USER=${POSTGRES_USER:-ape}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-ape_timescale_password}
      - POSTGRES_DB=${POSTGRES_DB:-ape_timeseries}

      # Performance (shared_buffers = 25% of RAM, effective_cache_size = 50% of RAM)
      - POSTGRES_SHARED_BUFFERS=1GB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=2GB
      - POSTGRES_WORK_MEM=16MB
      - POSTGRES_MAINTENANCE_WORK_MEM=256MB

      # TimescaleDB specific
      - TIMESCALEDB_TELEMETRY=off

    volumes:
      - timescaledb_data:/var/lib/postgresql/data
      # Init scripts (создание hypertables)
      - ./init_scripts/timescaledb:/docker-entrypoint-initdb.d

    command:
      - "postgres"
      - "-c"
      - "max_connections=100"
      - "-c"
      - "shared_buffers=1GB"
      - "-c"
      - "effective_cache_size=2GB"
      - "-c"
      - "work_mem=16MB"
      - "-c"
      - "maintenance_work_mem=256MB"
      - "-c"
      - "random_page_cost=1.1"
      - "-c"
      - "effective_io_concurrency=200"
      - "-c"
      - "wal_buffers=16MB"
      - "-c"
      - "min_wal_size=1GB"
      - "-c"
      - "max_wal_size=4GB"

    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ape} -d ${POSTGRES_DB:-ape_timeseries}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

    networks:
      - ape-network

  # ============================================================================
  # Redis - Caching Layer (L2 cache для API responses)
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: ape-redis
    restart: unless-stopped

    ports:
      - "6380:6379"

    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru

    volumes:
      - redis_data:/data

    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

    networks:
      - ape-network

  # ============================================================================
  # Prometheus - Metrics Collection
  # ============================================================================
  prometheus:
    image: prom/prometheus:latest
    container_name: ape-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    networks:
      - ape-network
    depends_on:
      - api

  # ============================================================================
  # Grafana - Metrics Visualization
  # ============================================================================
  grafana:
    image: grafana/grafana:latest
    container_name: ape-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./config/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - ape-network

# ==============================================================================
# Volumes (persistent storage)
# ==============================================================================
volumes:
  neo4j_data:
    name: ape_neo4j_data
  neo4j_logs:
    name: ape_neo4j_logs
  neo4j_import:
    name: ape_neo4j_import
  neo4j_plugins:
    name: ape_neo4j_plugins

  timescaledb_data:
    name: ape_timescaledb_data

  redis_data:
    name: ape_redis_data

  prometheus_data:
    name: ape_prometheus_data

  grafana_data:
    name: ape_grafana_data

  vee_workspace:
    name: ape_vee_workspace

# ==============================================================================
# Networks
# ==============================================================================
networks:
  ape-network:
    name: ape-network
    driver: bridge
